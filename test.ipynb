{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from fer import FER\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = \"C:/Collage/GP/My_Social_Eye/Speaker_Detection/face_landmarks/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# load the dlib feature extractor and face detector:\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the video:\n",
    "TestDir = \"C:\\\\Collage\\\\GP\\\\test\\\\\"\n",
    "cap = cv2.VideoCapture(TestDir+\"sleep.mp4\")\n",
    "success, img = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(418, 204) (803, 590)]\n"
     ]
    }
   ],
   "source": [
    "#dlib face detector\n",
    "dets = detector(img, 1)\n",
    "for _, d in enumerate(dets):\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[380 116 489 489]\n",
      "[(380, 116) (869, 605)]\n"
     ]
    }
   ],
   "source": [
    "#cascade face detector\n",
    "from Emotions_Detection.Models.face_detection import get_faces_from_image\n",
    "\n",
    "faces = get_faces_from_image(img, is_dir=False, is_gray=False)\n",
    "for face in faces:\n",
    "    print(face)\n",
    "\n",
    "    #convert it to dlib rectangle\n",
    "    dlib_rect = dlib.rectangle(face[0], face[1], face[0]+face[2], face[1]+face[3])\n",
    "    print(dlib_rect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min area 426\n",
      "max area 538\n",
      "avg area 450.3445945945946\n"
     ]
    }
   ],
   "source": [
    "#cascade face detector\n",
    "from Emotions_Detection.Models.face_detection import get_faces_from_image\n",
    "# load the video:\n",
    "TestDir = \"C:\\\\Collage\\\\GP\\\\test\\\\\"\n",
    "cap = cv2.VideoCapture(TestDir+\"speaking_challenge.mp4\")\n",
    "success, img = cap.read()\n",
    "areas = []\n",
    "while success:\n",
    "    faces = get_faces_from_image(img, is_dir=False, is_gray=False)\n",
    "    for face in faces:\n",
    "        area = face[2]\n",
    "        areas.append(area)\n",
    "    success, img = cap.read()\n",
    "areas = np.array(areas)\n",
    "print('min area', np.min(areas))\n",
    "print('max area', np.max(areas))\n",
    "print('avg area', np.mean(areas))\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min area 481\n",
      "max area 514\n",
      "avg area 500.5913043478261\n"
     ]
    }
   ],
   "source": [
    "#cascade face detector\n",
    "from Emotions_Detection.Models.face_detection import get_faces_from_image\n",
    "# load the video:\n",
    "TestDir = \"C:\\\\Collage\\\\GP\\\\test\\\\\"\n",
    "cap = cv2.VideoCapture(TestDir+\"no_speak.mp4\")\n",
    "success, img = cap.read()\n",
    "areas = []\n",
    "while success:\n",
    "    faces = get_faces_from_image(img, is_dir=False, is_gray=False)\n",
    "    for face in faces:\n",
    "        area = face[2]\n",
    "        areas.append(area)\n",
    "    success, img = cap.read()\n",
    "areas = np.array(areas)\n",
    "print('min area', np.min(areas))\n",
    "print('max area', np.max(areas))\n",
    "print('avg area', np.mean(areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AAC860D820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AAC860D820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AAC860D820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AAC860D820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.72, 'disgust': 0.0, 'fear': 0.27, 'happy': 0.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# a fast Emotion Detector to test CU:\n",
    "detector = FER(mtcnn=True)\n",
    "# emotion, score = detector.top_emotion(img)\n",
    "# print(emotion,score)\n",
    "emotions = detector.detect_emotions(img)[0][\"emotions\"]\n",
    "print(emotions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cdc2ecdd60dced0a09eee11361aead9c88c611efee536d4cb0c0677d944af6b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cufe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
