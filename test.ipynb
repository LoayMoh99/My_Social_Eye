{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from fer import FER\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = \"C:/Collage/GP/My_Social_Eye/Speaker_Detection/face_landmarks/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# load the dlib feature extractor and face detector:\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the video:\n",
    "TestDir = \"C:\\\\Collage\\\\GP\\\\test\\\\\"\n",
    "cap = cv2.VideoCapture(TestDir+\"no_speak.mp4\")\n",
    "success, img = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(418, 204) (803, 590)]\n"
     ]
    }
   ],
   "source": [
    "#dlib face detector\n",
    "dets = detector(img, 1)\n",
    "for _, d in enumerate(dets):\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[380 116 489 489]\n",
      "[(380, 116) (869, 605)]\n"
     ]
    }
   ],
   "source": [
    "#cascade face detector\n",
    "from Emotions_Detection.Models.face_detection import get_faces_from_image\n",
    "\n",
    "faces = get_faces_from_image(img, is_dir=False, is_gray=False)\n",
    "for face in faces:\n",
    "    print(face)\n",
    "\n",
    "    #convert it to dlib rectangle\n",
    "    dlib_rect = dlib.rectangle(face[0], face[1], face[0]+face[2], face[1]+face[3])\n",
    "    print(dlib_rect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min area 426\n",
      "max area 538\n",
      "avg area 450.3445945945946\n"
     ]
    }
   ],
   "source": [
    "#cascade face detector\n",
    "from Emotions_Detection.Models.face_detection import get_faces_from_image\n",
    "# load the video:\n",
    "TestDir = \"C:\\\\Collage\\\\GP\\\\test\\\\\"\n",
    "cap = cv2.VideoCapture(TestDir+\"speaking_challenge.mp4\")\n",
    "success, img = cap.read()\n",
    "areas = []\n",
    "while success:\n",
    "    faces = get_faces_from_image(img, is_dir=False, is_gray=False)\n",
    "    for face in faces:\n",
    "        area = face[2]\n",
    "        areas.append(area)\n",
    "    success, img = cap.read()\n",
    "areas = np.array(areas)\n",
    "print('min area', np.min(areas))\n",
    "print('max area', np.max(areas))\n",
    "print('avg area', np.mean(areas))\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min area 481\n",
      "max area 514\n",
      "avg area 500.5913043478261\n"
     ]
    }
   ],
   "source": [
    "#cascade face detector\n",
    "from Emotions_Detection.Models.face_detection import get_faces_from_image\n",
    "# load the video:\n",
    "TestDir = \"C:\\\\Collage\\\\GP\\\\test\\\\\"\n",
    "cap = cv2.VideoCapture(TestDir+\"no_speak.mp4\")\n",
    "success, img = cap.read()\n",
    "areas = []\n",
    "while success:\n",
    "    faces = get_faces_from_image(img, is_dir=False, is_gray=False)\n",
    "    for face in faces:\n",
    "        area = face[2]\n",
    "        areas.append(area)\n",
    "    success, img = cap.read()\n",
    "areas = np.array(areas)\n",
    "print('min area', np.min(areas))\n",
    "print('max area', np.max(areas))\n",
    "print('avg area', np.mean(areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.72, 'disgust': 0.0, 'fear': 0.27, 'happy': 0.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# a fast Emotion Detector to test CU:\n",
    "detector = FER(mtcnn=True)\n",
    "# emotion, score = detector.top_emotion(img)\n",
    "# print(emotion,score)\n",
    "emotions = detector.detect_emotions(img)[0][\"emotions\"]\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, img = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.76, 'disgust': 0.0, 'fear': 0.23, 'happy': 0.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n",
      "{'angry': 1.48, 'disgust': 0.0, 'fear': 0.5, 'happy': 0.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n"
     ]
    }
   ],
   "source": [
    "emotions1 = detector.detect_emotions(img)[0][\"emotions\"]\n",
    "print(emotions1)\n",
    "for key, value in emotions.items():\n",
    "    emotions1[key] += value\n",
    "print(emotions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.72, 'disgust': 0.0, 'fear': 0.27, 'happy': 0.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 0.0}\n"
     ]
    }
   ],
   "source": [
    "emotion2 = {}\n",
    "for key, value in emotions.items():\n",
    "    if key in emotion2:\n",
    "        emotion2[key] += value\n",
    "    else:\n",
    "        emotion2[key] = value\n",
    "print(emotion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceData:\n",
    "    def __init__(self, face_position=[], isMasked=None, emotion=None, mouthState=None):\n",
    "        self.face_position = face_position\n",
    "        # this is the square root area\n",
    "        self.face_area = face_position[3] if len(face_position)>0 else 0\n",
    "        self.isMasked = isMasked\n",
    "        self.emotion = emotion\n",
    "        self.mouthState = mouthState\n",
    "    def __str__(self):\n",
    "        return \"FaceData: \" + str(self.face_position) + \" \"+ str(self.face_area)+\" \"+str(self.isMasked) + \" \" + str(self.emotion) + \" \" + str(self.mouthState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = get_faces_from_image(img, is_dir=False, is_gray=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceData: [380 116 489 489] 489 None None None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frameFaceData = []\n",
    "faceData = FaceData(face_position=faces[0])\n",
    "\n",
    "frameFaceData.append(faceData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceData: [380 116 489 489] 489 None None None\n",
      "FaceData: [310 128 485 485] 485 None None None\n",
      "FaceData: [310 128 485 485] 485 None None None\n"
     ]
    }
   ],
   "source": [
    "faceData2 = FaceData(face_position=faces[0])\n",
    "frameFaceData.append(faceData2)\n",
    "frameFaceData = sorted(\n",
    "    frameFaceData, key=lambda x: x.face_area , reverse=True)\n",
    "for faceData in frameFaceData:\n",
    "    print(str(faceData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.format_version"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cdc2ecdd60dced0a09eee11361aead9c88c611efee536d4cb0c0677d944af6b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cufe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
