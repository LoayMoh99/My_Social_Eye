{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "current = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)\n",
    "from Emotions_Detection.Models.features import GabourFeatures\n",
    "from Emotions_Detection.Assets.CommonFuntions import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Vaiables\n",
    "IMG_TRAIN_PATH = \"../Assets/data/train\"\n",
    "IMG_TEST_PATH = \"../Assets/data/test\"\n",
    "HAPPY_PATH = \"../Assets/data/train/happy/\"\n",
    "\n",
    "train_folders = os.listdir(IMG_TRAIN_PATH)  # Emotions Folders\n",
    "test_folders = os.listdir(IMG_TEST_PATH)  # Emotions Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry 3995\n",
      "happy 7215\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\Emotions_Detection\\tests\\gabor_filters.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/tests/gabor_filters.ipynb#ch0000002?line=0'>1</a>\u001b[0m train_imgs, y_train \u001b[39m=\u001b[39m read_data(IMG_TRAIN_PATH)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/tests/gabor_filters.ipynb#ch0000002?line=1'>2</a>\u001b[0m test_imgs, y_test \u001b[39m=\u001b[39m read_data(IMG_TEST_PATH)\n",
      "File \u001b[1;32mF:\\Grad. Project\\GP2\\Codes\\repo_emotion\\Emotions_Detection\\Assets\\CommonFuntions.py:39\u001b[0m, in \u001b[0;36mread_data\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=36'>37</a>\u001b[0m     \u001b[39mprint\u001b[39m(folder, \u001b[39mlen\u001b[39m(imgs))\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=37'>38</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(imgs)):\n\u001b[1;32m---> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=38'>39</a>\u001b[0m         x_images\u001b[39m.\u001b[39mappend(read_and_process(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(folder_path, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mim\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=39'>40</a>\u001b[0m         y_images\u001b[39m.\u001b[39mappend(folder)\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x_images, y_images\n",
      "File \u001b[1;32mF:\\Grad. Project\\GP2\\Codes\\repo_emotion\\Emotions_Detection\\Assets\\CommonFuntions.py:25\u001b[0m, in \u001b[0;36mread_and_process\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=21'>22</a>\u001b[0m \u001b[39m''' Here we apply all kinds of preprocessing for the training images before supplying\u001b[39;00m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=22'>23</a>\u001b[0m \u001b[39m    the feature generation models'''\u001b[39;00m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=23'>24</a>\u001b[0m \u001b[39m# Read and convert to Gray\u001b[39;00m\n\u001b[1;32m---> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=24'>25</a>\u001b[0m img \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mimread(img_path, as_gray\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=25'>26</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Assets/CommonFuntions.py?line=26'>27</a>\u001b[0m \u001b[39m# img = img[12:, :]\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_io.py?line=49'>50</a>\u001b[0m         plugin \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtifffile\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_io.py?line=51'>52</a>\u001b[0m \u001b[39mwith\u001b[39;00m file_or_url_context(fname) \u001b[39mas\u001b[39;00m fname:\n\u001b[1;32m---> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_io.py?line=52'>53</a>\u001b[0m     img \u001b[39m=\u001b[39m call_plugin(\u001b[39m'\u001b[39m\u001b[39mimread\u001b[39m\u001b[39m'\u001b[39m, fname, plugin\u001b[39m=\u001b[39mplugin, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mplugin_args)\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_io.py?line=54'>55</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(img, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_io.py?line=55'>56</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\skimage\\io\\manage_plugins.py:207\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/manage_plugins.py?line=202'>203</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/manage_plugins.py?line=203'>204</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not find the plugin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/manage_plugins.py?line=204'>205</a>\u001b[0m                            (plugin, kind))\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/manage_plugins.py?line=206'>207</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:10\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_plugins/imageio_plugin.py?line=7'>8</a>\u001b[0m \u001b[39m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m      <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_plugins/imageio_plugin.py?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/skimage/io/_plugins/imageio_plugin.py?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(imageio_imread(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\__init__.py:86\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/__init__.py?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(uri, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/__init__.py?line=65'>66</a>\u001b[0m     \u001b[39m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/__init__.py?line=66'>67</a>\u001b[0m \n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/__init__.py?line=67'>68</a>\u001b[0m \u001b[39m    Reads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/__init__.py?line=83'>84</a>\u001b[0m \u001b[39m        to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/__init__.py?line=84'>85</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/__init__.py?line=85'>86</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m imread_v2(uri, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\v2.py:159\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/v2.py?line=153'>154</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/v2.py?line=154'>155</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/v2.py?line=155'>156</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mInvalid keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m \u001b[39m'\u001b[39m\u001b[39mperhaps you mean \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpilmode\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/v2.py?line=156'>157</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/v2.py?line=158'>159</a>\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39;49m\u001b[39mri\u001b[39;49m\u001b[39m\"\u001b[39;49m, plugin\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/v2.py?line=159'>160</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m file\u001b[39m.\u001b[39mread(index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\core\\imopen.py:254\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/imopen.py?line=250'>251</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/imopen.py?line=252'>253</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/imopen.py?line=253'>254</a>\u001b[0m     plugin_instance \u001b[39m=\u001b[39m candidate_plugin(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/imopen.py?line=254'>255</a>\u001b[0m \u001b[39mexcept\u001b[39;00m InitializationError:\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/imopen.py?line=255'>256</a>\u001b[0m     \u001b[39m# file extension doesn't match file type\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/imopen.py?line=256'>257</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\config\\plugins.py:108\u001b[0m, in \u001b[0;36mPluginConfig.plugin_class.<locals>.partial_legacy_plugin\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/config/plugins.py?line=106'>107</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpartial_legacy_plugin\u001b[39m(request):\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/config/plugins.py?line=107'>108</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m LegacyPlugin(request, legacy_plugin)\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py:68\u001b[0m, in \u001b[0;36mLegacyPlugin.__init__\u001b[1;34m(self, request, legacy_plugin)\u001b[0m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=61'>62</a>\u001b[0m source \u001b[39m=\u001b[39m (\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=62'>63</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<bytes>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=63'>64</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request\u001b[39m.\u001b[39mraw_uri, \u001b[39mbytes\u001b[39m)\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=64'>65</a>\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request\u001b[39m.\u001b[39mraw_uri\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=65'>66</a>\u001b[0m )\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mio_mode \u001b[39m==\u001b[39m IOMode\u001b[39m.\u001b[39mread:\n\u001b[1;32m---> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=67'>68</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format\u001b[39m.\u001b[39;49mcan_read(request):\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=68'>69</a>\u001b[0m         \u001b[39mraise\u001b[39;00m InitializationError(\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=69'>70</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m can not read `\u001b[39m\u001b[39m{\u001b[39;00msource\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=70'>71</a>\u001b[0m         )\n\u001b[0;32m     <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/legacy_plugin_wrapper.py?line=71'>72</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\core\\format.py:211\u001b[0m, in \u001b[0;36mFormat.can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/format.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcan_read\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/format.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"can_read(request)\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/format.py?line=207'>208</a>\u001b[0m \n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/format.py?line=208'>209</a>\u001b[0m \u001b[39m    Get whether this format can read data from the specified uri.\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/format.py?line=209'>210</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/format.py?line=210'>211</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_can_read(request)\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\plugins\\pillow_legacy.py:269\u001b[0m, in \u001b[0;36mPillowFormat._can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/plugins/pillow_legacy.py?line=266'>267</a>\u001b[0m factory, accept \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mOPEN[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplugin_id]\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/plugins/pillow_legacy.py?line=267'>268</a>\u001b[0m \u001b[39mif\u001b[39;00m accept:\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/plugins/pillow_legacy.py?line=268'>269</a>\u001b[0m     \u001b[39mif\u001b[39;00m request\u001b[39m.\u001b[39;49mfirstbytes \u001b[39mand\u001b[39;00m accept(request\u001b[39m.\u001b[39mfirstbytes):\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/plugins/pillow_legacy.py?line=269'>270</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\core\\request.py:586\u001b[0m, in \u001b[0;36mRequest.firstbytes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=581'>582</a>\u001b[0m \u001b[39m\"\"\"The first 256 bytes of the file. These can be used to\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=582'>583</a>\u001b[0m \u001b[39mparse the header to determine the file-format.\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=583'>584</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=584'>585</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_firstbytes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=585'>586</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_first_bytes()\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=586'>587</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_firstbytes\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\core\\request.py:595\u001b[0m, in \u001b[0;36mRequest._read_first_bytes\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=591'>592</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=592'>593</a>\u001b[0m     \u001b[39m# Prepare\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=593'>594</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=594'>595</a>\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_file()\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=595'>596</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=596'>597</a>\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename):  \u001b[39m# A directory, e.g. for DICOM\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\venv\\lib\\site-packages\\imageio\\core\\request.py:473\u001b[0m, in \u001b[0;36mRequest.get_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=470'>471</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=471'>472</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=472'>473</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=474'>475</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_uri_type \u001b[39m==\u001b[39m URI_ZIPPED:\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=475'>476</a>\u001b[0m     \u001b[39m# Get the correct filename\u001b[39;00m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/venv/lib/site-packages/imageio/core/request.py?line=476'>477</a>\u001b[0m     filename, name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename_zip\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_imgs, y_train = read_data(IMG_TRAIN_PATH)\n",
    "test_imgs, y_test = read_data(IMG_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mf:\\Grad. Project\\GP2\\Codes\\repo_emotion\\Emotions_Detection\\tests\\gabor_filters.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/tests/gabor_filters.ipynb#ch0000008?line=2'>3</a>\u001b[0m gb_feats_test \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/tests/gabor_filters.ipynb#ch0000008?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m train_imgs:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/tests/gabor_filters.ipynb#ch0000008?line=4'>5</a>\u001b[0m     gb_feats_train\u001b[39m.\u001b[39mappend(gb_cls\u001b[39m.\u001b[39;49mcompute(img))\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/tests/gabor_filters.ipynb#ch0000008?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m test_imgs:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/tests/gabor_filters.ipynb#ch0000008?line=7'>8</a>\u001b[0m     gb_feats_test\u001b[39m.\u001b[39mappend(gb_cls\u001b[39m.\u001b[39mcompute(img))\n",
      "File \u001b[1;32mF:\\Grad. Project\\GP2\\Codes\\repo_emotion\\Emotions_Detection\\Models\\features.py:264\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Models/features.py?line=262'>263</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, image):\n\u001b[1;32m--> <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Models/features.py?line=263'>264</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mapply the filters to the image to get the features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Models/features.py?line=264'>265</a>\u001b[0m     features \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///f%3A/Grad.%20Project/GP2/Codes/repo_emotion/Emotions_Detection/Models/features.py?line=265'>266</a>\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39mfilter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters:\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gb_cls = GabourFeatures()\n",
    "gb_feats_train = []\n",
    "gb_feats_test = []\n",
    "for img in train_imgs:\n",
    "    gb_feats_train.append(gb_cls.compute(img))\n",
    "\n",
    "for img in test_imgs:\n",
    "    gb_feats_test.append(gb_cls.compute(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(gb_feats_train)\n",
    "x_test = np.array(gb_feats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fac903841471747198614399c2b636b7d1738aa157e41a1819b23ccf7e493167"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
